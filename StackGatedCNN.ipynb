{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam, SGD\n",
    "from transformers import BertModel\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'downloads/train_set.csv'\n",
    "test_data_path = 'downloads/test_a.csv'\n",
    "train_data = pd.read_csv(train_data_path, sep='\\t', encoding='UTF-8')\n",
    "test_data = pd.read_csv(test_data_path, sep='\\t', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2967 6758 339 2021 1854 3731 4109 3792 4149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4464 486 6352 5619 2465 4802 1452 3137 5778 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7346 4068 5074 3747 5681 6093 1777 2226 7354 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7159 948 4866 2109 5520 2490 211 3956 5520 549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3646 3055 3055 2490 4659 6065 3370 5814 2465 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  2967 6758 339 2021 1854 3731 4109 3792 4149 15...\n",
       "1     11  4464 486 6352 5619 2465 4802 1452 3137 5778 54...\n",
       "2      3  7346 4068 5074 3747 5681 6093 1777 2226 7354 6...\n",
       "3      2  7159 948 4866 2109 5520 2490 211 3956 5520 549...\n",
       "4      3  3646 3055 3055 2490 4659 6065 3370 5814 2465 5..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lable 数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[\"label\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text 数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2967 6758 339 2021 1854 3731 4109 3792 4149 1519 2058 3912 2465 2410 1219 6654 7539 264 2456 4811 1292 2109 6905 5520 7058 6045 3634 6591 3530 6508 2465 7044 1519 3659 2073 3750 3731 4109 3792 6831 2614 3370 4269 3370 486 5770 4109 4125 3750 5445 2466 6831 6758 3743 3630 1726 2313 5906 826 4516 657 900 1871 7044 3750 2967 3731 1757 1939 648 2828 4704 7039 3706 3750 965 2490 7399 3743 2145 2407 7451 3775 6017 5998 1641 299 4704 2621 7029 3056 6333 433 648 1667 1099 900 2289 1099 648 5780 220 7044 1279 7426 4269 3750 2967 6758 6631 3099 2205 7305 2620 5977 3750 3329 1793 6666 2042 3193 4149 1519 7039 3706 2446 5399 648 4124 2058 3912 248 3193 2252 5649 2212 4939 7239 3310 4525 2400 900 5770 4109 4125 7044 4921 265 1397 4699 1699 669 6407 3750 1271 1271 4741 669 4659 3870 4030 4167 5338 25 3466 6909 4417 1859 3750 1465 7194 648 3938 1571 848 6986 827 2124 3750 1991 7444 7037 2729 908 6308 3750 1889 6810 4190 591 5598 2289 2109 6831 6407 2400 5410 517 900 25 3731 4109 3792 4128 1679 4811 4853 4109 3630 6902 6122 1903 1736 3915 2602 6822 3750 6630 4265 591 729 4448 648 1465 1401 4853 648 5881 6182 4128 1679 4939 2646 652 340 7328 1320 900 1460 619 5505 2376 4853 3272 3750 4853 4109 3630 6902 3362 2810 3750 803 1985 4128 669 19 6508 900 1635 1871 7377 6122 6017 3750 2289 1099 3938 1571 7509 1375 5393 5589 5037 2115 4707 5310 6811 6093 900 7399 2410 1219 6654 3263 6017 3750 5998 4939 5971 4148 3750 803 1985 7194 4780 796 6038 4231 648 1722 6407 3750 1099 6485 1920 1767 5915 6518 6093 5598 5648 4280 900 7326 6242 5328 1214 3870 1985 7194 5998 5741 2115 913 5950 3800 1538 686 6734 6017 3750 1985 3659 1324 5814 4998 5176 535 7399 307 4068 486 1667 1099 2121 6407 3750 7420 3099 6038 4231 4190 1519 3255 7123 4305 3231 1635 4822 1722 3750 2967 3731 1757 1939 648 473 6518 2400 2614 5330 5530 1394 4939 1903 7495 7239 900 4469 5530 4704 299 7467 2121 669 5693 3750 3618 299 5264 4853 1734 316 2828 5445 4190 4939 3484 6043 2376 1031 761 900 5370 3782 2210 669 2210 3099 1363 6301 3508 1907 2410 7509 5718 541 3750 803 2967 6758 3038 6641 1985 7194 512 4811 6811 5243 2112 3750 1734 2376 2891 1211 648 7257 4148 7159 1667 3750 5816 4202 2400 5864 3915 7399 3414 1667 5977 7327 7256 2935 4936 1667 2151 900 6831 4599 6182 3227 3859 3099 7509 7256 3750 1985 7194 4128 4691 2029 1344 6630 5598 1465 648 3706 7403 543 3038 900 1985 7194 3800 980 6017 980 4124 648 900 1635 3605 5028 3731 4109 3792 1866 3578 3915 648 4939 1335 6666 6560 3750 3618 3508 1907 2410 1913 6656 3750 2828 4704 4998 4939 7039 3915 4167 5338 3750 803 1985 4939 3263 7123 264 2456 5689 2109 648 3750 6093 1699 5589 4411 1866 4750 648 1667 1099 3000 7420 1279 2975 1141 7148 3750 1985 3915 2570 4936 5998 1877 3000 7420 900 1635 5470 2313 5864 641 4333 3750 3915 5659 316 2828 2770 5176 803 2047 7532 606 6980 1635 3750 803 1750 7039 3800 7245 3099 7509 5839 3750 1866 1401 4321 5788 1519 6122 6405 4939 5998 2729 900 1985 7194 5998 2289 2107 1519 1592 316 2828 1679 4811 5461 3324 4525 4052 3750 2212 742 3750 1985 7194 6631 1335 5445 3750 1465 7194 4128 6887 4819 5977 3223 2717 900 5612 5948 3750 1985 7194 2289 913 3800 4811 6122 2614 2047 7532 606 6980 900 1985 2541 4409 3772 6012 1833 5560 4173 6662 414 340 316 4125 4128 3800 669 6575 4819 5977 900 1635 25 1460 619 7044 4921 648 4407 3800 1241 600 3750 5470 2313 641 4333 7539 803 316 4125 648 3530 6637 569 1985 3000 4659 5610 6917 3750 3618 1985 6887 7010 3870 900 3915 4939 7010 3870 5598 1985 1394 3397 5598 900 1635 1460 619 5708 1335 6518 4148 3750 2410 1219 6654 2252 1702 5598 803 4646 2109 6905 5520 1635 2663 885 5491 1465 4822 1722 5011 2376 4149 1903 2662 3750 803 316 2828 1767 5915 6065 2042 1335 5598 3750 2688 5598 3231 5780 7399 3750 4811 5788 1292 1641 1667 1099 4811 5393 6407 5708 6631 1335 6666 900 316 4125 4811 648 4939 6678 3750 2021 1726 340 4469 4842 4128 669 5393 4801 3154 3750 5780 7399 669 3915 544 62 5602 1913 5598 3750 3859 6759 4939 4646 1913 900 1635 1767 5915 6065 4464 5814 648 2410 1219 6654 1815 1699 6038 4231 5698 1375 62 307 3750 803 299 5264 1460 316 2828 5445 3750 1985 3414 1667 7509 3223 3750 5998 4939 669 2364 2975 648 900 1985 3038 5938 5168 3770 1667 3750 2717 368 5693 7117 3750 1985 2131 6909 2192 1141 6831 6015 900 3864 7194 1375 5393 1815 1699 1985 5780 7399 5681 3099 5176 3870 5598 3750 1985 3038 3771 6630 7159 1667 900 1635 5659 7377 3166 5445 3750 1793 6666 648 2614 5736 5537 5526 4128 6887 4811 495 6386 900 1465 7194 1767 5659 2410 1219 6654 340 1362 1829 2304 3193 6822 3750 5330 5264 4321 3750 4173 5619 4109 6227 648 5915 6515 4893 5957 6043 3750 5949 4411 5410 1991 4128 826 2490 3193 2602 3750 803 1985 7194 4516 5264 1394 3800 5659 3731 4109 3792 5081 2918 3750 5051 1985 5612 19 3750 3731 4109 3792 5718 7239 3193 6822 900 1635 7377 5736 3750 2205 7305 2620 2042 5192 1745 3605 6887 5278 299 648 5651 7440 1656 3630 1702 3300 7539 803 1985 340 3731 4109 3792 4190 4811 4464 1519 5778 3166 3750 1985 3038 6235 7399 5998 2313 900 1635 25 910 619 4939 1613 248 3193 4741 4893 3750 2967 3731 1757 1939 648 7495 5028 5949 4939 7539 803 4811 2255 3915 3750 1394 4741 900 6887 2255 3915 3750 1394 669 4741 900 1635'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字表长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7550\n"
     ]
    }
   ],
   "source": [
    "max_char=0\n",
    "for i in range(len(train_data)):\n",
    "    text_ls=train_data[\"text\"].iloc[i].split()\n",
    "    for num in text_ls:\n",
    "        if int(num) > max_char:\n",
    "            max_char = int(num)\n",
    "print(max_char+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text数据长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len_arr=np.array([len(x.split()) for x in train_data[\"text\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大文本长度： 57921\n",
      "最小文本长度： 2\n",
      "平均文本长度： 907.20711\n",
      "文本长度中位数： 676.0\n"
     ]
    }
   ],
   "source": [
    "print(\"最大文本长度：\",np.max(text_len_arr))\n",
    "print(\"最小文本长度：\",np.min(text_len_arr))\n",
    "print(\"平均文本长度：\",np.mean(text_len_arr))\n",
    "print(\"文本长度中位数：\",np.median(text_len_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别样本数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0     38918\n",
       "1     36945\n",
       "2     31425\n",
       "3     22133\n",
       "4     15016\n",
       "5     12232\n",
       "6      9985\n",
       "7      8841\n",
       "8      7847\n",
       "9      5878\n",
       "10     4920\n",
       "11     3131\n",
       "12     1821\n",
       "13      908\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5399 3117 1070 4321 4568 2621 5466 3772 4516 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2491 4109 1757 7539 648 3695 3038 4490 23 7019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2673 5076 6835 2835 5948 5677 3247 4124 2465 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4562 4893 2210 4761 3659 1324 2595 5949 4583 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4269 7134 2614 1724 4464 1324 3370 3370 2106 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  5399 3117 1070 4321 4568 2621 5466 3772 4516 2...\n",
       "1  2491 4109 1757 7539 648 3695 3038 4490 23 7019...\n",
       "2  2673 5076 6835 2835 5948 5677 3247 4124 2465 5...\n",
       "3  4562 4893 2210 4761 3659 1324 2595 5949 4583 2...\n",
       "4  4269 7134 2614 1724 4464 1324 3370 3370 2106 2..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每个类别按比例拆分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179993\n",
      "20007\n"
     ]
    }
   ],
   "source": [
    "test_size=0.1\n",
    "train_data_ls=[]\n",
    "test_data_ls=[]\n",
    "for label in set(train_data[\"label\"].values):\n",
    "    sub_data=train_data[train_data[\"label\"]==label]\n",
    "    sub_data_train,sub_data_test=train_test_split(sub_data,test_size=test_size)\n",
    "    train_data_ls.append(sub_data_train)\n",
    "    test_data_ls.append(sub_data_test)\n",
    "train_data_concat=pd.concat(train_data_ls,axis=0)\n",
    "test_data_concat=pd.concat(test_data_ls,axis=0)\n",
    "print(len(train_data_concat))\n",
    "print(len(test_data_concat))\n",
    "train_data_concat.to_csv(\"datasets/train_data.csv\",index=False)\n",
    "test_data_concat.to_csv(\"datasets/valid_data.csv\",index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"max_length\":2000,\n",
    "        \"batch_size\":128,\n",
    "        \"train_data_path\":'downloads/132889/train_set.csv',\n",
    "        \"class_num\":14,\n",
    "        \"num_layers\":2,\n",
    "        \"hidden_size\":512,\n",
    "        \"pooling_style\":\"max\",\n",
    "        \"train_data_path\":\"datasets/train_data.csv\",\n",
    "        \"valid_data_path\":\"datasets/valid_data.csv\",\n",
    "        \"test_data_path\":\"downloads/test_a.csv\",\n",
    "        \"model_path\":\"model/model.pth\",\n",
    "        \"optimizer\":\"adam\",\n",
    "        \"learning_rate\":0.001,\n",
    "        \"epoch\":3,\n",
    "        \"kernel_size\": 3,\n",
    "        \"vocab_size\":7550,\n",
    "       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, data_path, config):\n",
    "        self.data_path = data_path\n",
    "        self.config = config\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        self.data = []\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        for i in range(len(df)):\n",
    "            sequence=[int(x) for x in df[\"text\"].iloc[i].split()]\n",
    "            encode_x = torch.LongTensor(padding(sequence,config))\n",
    "            encode_y= torch.LongTensor([df[\"label\"].iloc[i]])\n",
    "            self.data.append([encode_x,encode_y])\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "\n",
    "\n",
    "def padding(input_sequence, config):\n",
    "    input_sequence = input_sequence[:config[\"max_length\"]]\n",
    "    input_sequence += [0] * (config[\"max_length\"] - len(input_sequence))\n",
    "    return input_sequence\n",
    "\n",
    "\n",
    "def load_data(data_path, config, shuffle=True):\n",
    "    dg = DataGenerator(data_path, config)\n",
    "    dl = DataLoader(dg, batch_size=config[\"batch_size\"], shuffle=shuffle)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([4118, 5176, 4559,  ...,    0,    0,    0]), tensor([0])]\n"
     ]
    }
   ],
   "source": [
    "dg = DataGenerator(config[\"train_data_path\"], config)\n",
    "print(dg[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNN, self).__init__()\n",
    "        hidden_size = config[\"hidden_size\"]  # 输入输出通道数\n",
    "        kernel_size = config[\"kernel_size\"]  # 卷积核尺寸\n",
    "        pad = int((kernel_size - 1) / 2)  # 添加pad保证卷积前后维度相同\n",
    "        self.cnn = nn.Conv1d(hidden_size, hidden_size, kernel_size, bias=False, padding=pad)\n",
    "\n",
    "    def forward(self, x):  # x : (batch_size, max_len, embeding_size)\n",
    "        return self.cnn(x.transpose(1, 2)).transpose(1, 2)\n",
    "    \n",
    "class GatedCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GatedCNN, self).__init__()\n",
    "        self.cnn = CNN(config)\n",
    "        self.gate = CNN(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.cnn(x)\n",
    "        b = self.gate(x)\n",
    "        b = torch.sigmoid(b)\n",
    "        return torch.mul(a, b)  # 逐个元素相乘，门控的作用相当于给每个元素添加权重\n",
    "    \n",
    "class StackGatedCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(StackGatedCNN, self).__init__()\n",
    "        self.num_layers = config[\"num_layers\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        # ModuleList类内可以放置多个模型，取用时类似于一个列表\n",
    "        self.gcnn_layers = nn.ModuleList(\n",
    "            GatedCNN(config) for i in range(self.num_layers)\n",
    "        )\n",
    "        self.ff_liner_layers1 = nn.ModuleList(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.num_layers)\n",
    "        )\n",
    "        self.ff_liner_layers2 = nn.ModuleList(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size) for i in range(self.num_layers)\n",
    "        )\n",
    "        self.bn_after_gcnn = nn.ModuleList(\n",
    "            nn.LayerNorm(self.hidden_size) for i in range(self.num_layers)\n",
    "        )\n",
    "        self.bn_after_ff = nn.ModuleList(\n",
    "            nn.LayerNorm(self.hidden_size) for i in range(self.num_layers)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # 仿照bert的transformer模型结构，将self-attention替换为gcnn\n",
    "        for i in range(self.num_layers):\n",
    "            gcnn_x = self.gcnn_layers[i](x)\n",
    "            x = gcnn_x + x  # 通过gcnn+残差\n",
    "            x = self.bn_after_gcnn[i](x)  # 之后bn\n",
    "            # # 仿照feed-forward层，使用两个线性层\n",
    "            l1 = self.ff_liner_layers1[i](x)  # 一层线性\n",
    "            l1 = torch.relu(l1)  # 在bert中这里是gelu\n",
    "            l2 = self.ff_liner_layers2[i](l1)  # 二层线性\n",
    "            x = self.bn_after_ff[i](x + l2)  # 残差后过bn\n",
    "        return x\n",
    "    \n",
    "class TorchModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TorchModel, self).__init__()\n",
    "        hidden_size = config[\"hidden_size\"]\n",
    "        class_num = config[\"class_num\"]\n",
    "        num_layers = config[\"num_layers\"]\n",
    "        vocab_size = config[\"vocab_size\"]\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=0)\n",
    "        self.encoder = StackGatedCNN(config)\n",
    "        self.classify = nn.Linear(hidden_size, class_num)\n",
    "        self.pooling_style = config[\"pooling_style\"]\n",
    "        self.loss = nn.functional.cross_entropy\n",
    "    \n",
    "    def forward(self, x, target=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        if isinstance(x, tuple):\n",
    "            x = x[0]\n",
    "        if self.pooling_style == \"max\":\n",
    "            self.pooling_layer = nn.MaxPool1d(x.shape[1])\n",
    "        else:\n",
    "            self.pooling_layer = nn.AvgPool1d(x.shape[1])\n",
    "        x = self.pooling_layer(x.transpose(1, 2)).squeeze()\n",
    "        predict = self.classify(x)\n",
    "        if target is not None:\n",
    "            return self.loss(predict, target.squeeze())\n",
    "        else:\n",
    "            return predict\n",
    "        \n",
    "def choose_optimizer(config, model):\n",
    "    optimizer = config[\"optimizer\"]\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "    if optimizer == \"adam\":\n",
    "        return Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        return SGD(model.parameters(), lr=learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self,config,model):\n",
    "        self.config=config\n",
    "        self.model=model\n",
    "        self.valid_data=load_data(self.config[\"valid_data_path\"],config)\n",
    "        self.state_dic={\"correct\":0,\"wrong\":0}\n",
    "\n",
    "    def eval(self,epoch):\n",
    "        print(\"开始测试第%d轮模型效果：\" % epoch)\n",
    "        self.model.eval()\n",
    "        self.state_dic={\"correct\":0,\"wrong\":0}\n",
    "        for index,batch_data in enumerate(self.valid_data):\n",
    "            if torch.cuda.is_available():\n",
    "                batch_data=[b.cuda() for b in batch_data]\n",
    "            input_ids,labels=batch_data\n",
    "            with torch.no_grad():\n",
    "                pred_result=self.model(input_ids)\n",
    "            self.write_stats(labels,pred_result)\n",
    "        acc=self.show_stats()\n",
    "        return acc\n",
    "\n",
    "    def write_stats(self,labels,pred_result):\n",
    "        assert  len(labels)==len(pred_result)\n",
    "        for true_label,pred_label in zip(labels,pred_result):\n",
    "            pred_label=torch.argmax(pred_label)\n",
    "            if int(true_label)==int(pred_label):\n",
    "                self.state_dic[\"correct\"]+=1\n",
    "            else:\n",
    "                self.state_dic[\"wrong\"]+=1\n",
    "        return\n",
    "\n",
    "    def show_stats(self):\n",
    "        correct=self.state_dic[\"correct\"]\n",
    "        wrong=self.state_dic[\"wrong\"]\n",
    "        print(\"预测集合条目总量：%d\" % (correct + wrong))\n",
    "        print(\"预测正确条目：%d，预测错误条目：%d\" % (correct, wrong))\n",
    "        print(\"预测准确率：%f\" % (correct / (correct + wrong)))\n",
    "        print(\"--------------------\")\n",
    "        return correct / (correct + wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    # 加载训练数据\n",
    "    train_data = load_data(config[\"train_data_path\"], config)\n",
    "    # 加载模型\n",
    "    model = TorchModel(config)\n",
    "    # 判断GPU是否可用\n",
    "    cuda_flag = torch.cuda.is_available()\n",
    "    if cuda_flag:\n",
    "        print(\"设备GPU可用，迁移模型至GPU\")\n",
    "        model = model.cuda()\n",
    "    # 加载优化器\n",
    "    optimizer = choose_optimizer(config, model)\n",
    "    # 加载模型训练效果\n",
    "    evaluator = Evaluator(config, model)\n",
    "    # 训练\n",
    "    for epoch in range(config[\"epoch\"]):\n",
    "        model.train()\n",
    "        print(\"epoch %d begin\" % epoch)\n",
    "        train_loss = []\n",
    "        for index, batch_data in tqdm(enumerate(train_data)):\n",
    "            if cuda_flag:\n",
    "                batch_data = [d.cuda() for d in batch_data]\n",
    "            optimizer.zero_grad()\n",
    "            input_ids, labels = batch_data\n",
    "            loss = model(input_ids, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            if index % 200 == 0:\n",
    "                print(\"batch loss %f\" % loss)\n",
    "        print(\"epoch average loss: %f\" % np.mean(train_loss))\n",
    "        acc = evaluator.eval(epoch)\n",
    "    torch.save(model.state_dict(), config[\"model_path\"])\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "设备GPU可用，迁移模型至GPU\n",
      "epoch 0 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 3.911251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:17,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.234336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [04:35,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.248294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [06:53,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.226673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [09:13,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.157625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [11:33,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.136669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [13:54,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.165293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [16:13,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.094761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1407it [16:17,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch average loss: 0.269014\n",
      "开始测试第0轮模型效果：\n",
      "预测集合条目总量：20007\n",
      "预测正确条目：18709，预测错误条目：1298\n",
      "预测准确率：0.935123\n",
      "--------------------\n",
      "epoch 1 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.195534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:22,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.102615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [04:44,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.114018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [07:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.139019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [09:20,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.151046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [11:41,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.064055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [14:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.136434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [16:23,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.354727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1407it [16:27,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch average loss: 0.154282\n",
      "开始测试第1轮模型效果：\n",
      "预测集合条目总量：20007\n",
      "预测正确条目：18853，预测错误条目：1154\n",
      "预测准确率：0.942320\n",
      "--------------------\n",
      "epoch 2 begin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.093485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [02:20,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.055522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [04:38,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.053100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [06:56,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.184178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [09:16,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.096344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [11:38,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.160484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [14:01,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.176824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [16:22,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss 0.139658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1407it [16:26,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch average loss: 0.109417\n",
      "开始测试第2轮模型效果：\n",
      "预测集合条目总量：20007\n",
      "预测正确条目：19020，预测错误条目：987\n",
      "预测准确率：0.950667\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "acc = main(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator:\n",
    "    def __init__(self, data_path, config):\n",
    "        self.data_path = data_path\n",
    "        self.config = config\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        self.data = []\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        for i in range(len(df)):\n",
    "            sequence=[int(x) for x in df[\"text\"].iloc[i].split()]\n",
    "            encode_x = torch.LongTensor(padding(sequence,config))\n",
    "            self.data.append(encode_x)\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "        \n",
    "def load_test_data(data_path, config, shuffle=True):\n",
    "    dg = TestDataGenerator(data_path, config)\n",
    "    dl = DataLoader(dg, batch_size=config[\"batch_size\"], shuffle=shuffle)\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(config):\n",
    "    test_data = load_test_data(config[\"test_data_path\"], config,shuffle=False)\n",
    "    model = TorchModel(config)\n",
    "    model.load_state_dict(torch.load(config[\"model_path\"]))\n",
    "    model.eval()\n",
    "    cuda_flag = torch.cuda.is_available()\n",
    "    if cuda_flag:\n",
    "        print(\"设备GPU可用，迁移模型至GPU\")\n",
    "        model = model.cuda()\n",
    "        result=[]\n",
    "    for index, batch_data in tqdm(enumerate(test_data)):\n",
    "        if cuda_flag:\n",
    "            batch_data = batch_data.cuda()\n",
    "        pred_result = model(batch_data)\n",
    "        result+=torch.argmax(pred_result,dim=1).tolist()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "设备GPU可用，迁移模型至GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [00:22, 17.06it/s]\n"
     ]
    }
   ],
   "source": [
    "result=predict_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"downloads/test_a_sample_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"]=result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"downloads/test_a_sample_submit.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
